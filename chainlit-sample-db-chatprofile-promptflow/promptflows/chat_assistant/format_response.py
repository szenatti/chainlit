from typing import Any, Dict

# For direct usage without promptflow runtime, we don't need the @tool decorator
def format_response(llm_output: str, profile_name: str) -> str:
    """
    Format the LLM response with profile-specific styling and metadata.
    
    Args:
        llm_output: Raw output from the LLM
        profile_name: Selected chat profile name
        
    Returns:
        Formatted response string with citations and metadata
    """
    
    # Profile-specific emojis and formatting
    profile_config = {
        "Assistant": {"emoji": "ğŸ¤–", "style": "standard"},
        "Creative": {"emoji": "ğŸ¨", "style": "creative"},
        "Analytical": {"emoji": "ğŸ“Š", "style": "analytical"},
        "Technical": {"emoji": "âš™ï¸", "style": "technical"},
        "Business": {"emoji": "ğŸ’¼", "style": "business"}
    }
    
    config = profile_config.get(profile_name, profile_config["Assistant"])
    
    # Add profile branding to response
    formatted_response = llm_output
    
    # Add citation information
    citation = f"\n\n---\n*Response generated by {config['emoji']} {profile_name} AI via Promptflow*"
    
    return formatted_response + citation 